{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "0b2c1b9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\czhao\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import ast\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import nltk\n",
    "nltk.download('words')\n",
    "words = set(nltk.corpus.words.words())\n",
    "\n",
    "def stemSentence_porter(sentence):\n",
    "    porter = PorterStemmer()\n",
    "    token_words=word_tokenize(sentence)\n",
    "    stem_sentence=[]\n",
    "    for word in token_words:\n",
    "        stem_sentence.append(porter.stem(word))\n",
    "        stem_sentence.append(\" \")\n",
    "    return \"\".join(stem_sentence)\n",
    "\n",
    "def convert(text):\n",
    "    L = []\n",
    "    for i in ast.literal_eval(text):\n",
    "        L.append(i['name']) \n",
    "    return L \n",
    "\n",
    "\n",
    "def fetch_director(text):\n",
    "    L = []\n",
    "    for i in ast.literal_eval(text):\n",
    "        if i['job'] == 'Director':\n",
    "            L.append(i['name'])\n",
    "    return L \n",
    "\n",
    "\n",
    "def collapse(L):\n",
    "    L1 = []\n",
    "    for i in L:\n",
    "        L1.append(i.replace(\" \",\"\"))\n",
    "    return L1\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "6e9c2e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -U sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "51f0e440",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = pd.read_csv('new_data/tmdb_5000_movies.csv')\n",
    "credits = pd.read_csv('new_data/tmdb_5000_credits.csv') \n",
    "movies = movies.merge(credits,on='title')\n",
    "movies = movies[['movie_id','title','overview','genres','keywords','cast','crew']]\n",
    "movies.dropna(inplace=True)\n",
    "movies['genres'] = movies['genres'].apply(convert)\n",
    "\n",
    "movies['keywords'] = movies['keywords'].apply(convert)\n",
    "\n",
    "movies['cast'] = movies['cast'].apply(convert)\n",
    "\n",
    "movies['cast'] = movies['cast'].apply(lambda x:x[0:3])\n",
    "\n",
    "movies['crew'] = movies['crew'].apply(fetch_director)\n",
    "\n",
    "\n",
    "movies['crew'] = movies['crew'].apply(lambda x: [\" \".join(\\\n",
    "        w for w in nltk.wordpunct_tokenize(i) \\\n",
    "         if w.lower() in words or not w.isalpha()) for i in x])\n",
    "\n",
    "# movies['cast'] = movies['cast'].apply(collapse)\n",
    "# movies['crew'] = movies['crew'].apply(collapse)\n",
    "# movies['genres'] = movies['genres'].apply(collapse)\n",
    "# movies['keywords'] = movies['keywords'].apply(collapse)\n",
    "\n",
    "movies['overview'] = movies['overview'].apply(lambda x:x.split())\n",
    "movies['tags'] = movies['overview'] + movies['genres'] + movies['keywords'] + movies['cast'] + movies['crew']\n",
    "new = movies.drop(columns=['overview','genres','keywords','cast','crew'])\n",
    "new['tags'] = new['tags'].apply(lambda x: \" \".join(x))\n",
    "new = new[(new['tags'].notnull())].reset_index(drop=True)\n",
    "# new['tags'] = new['tags'].apply(stemSentence_porter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "b6f134dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = SentenceTransformer('paraphrase-distilroberta-base-v1')\n",
    "# model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "# model = SentenceTransformer('all-mpnet-base-v2')\n",
    "model = SentenceTransformer('stsb-bert-large')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "9dd445dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptions = new['tags'].tolist()\n",
    "des_embeddings = []\n",
    "for i,des in enumerate(descriptions):\n",
    "    des_embeddings.append(model.encode(des))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "9cae30e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1024"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(des_embeddings[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "7a2f46a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend(query, model):\n",
    "    #Compute cosine-similarities with all embeddings \n",
    "    model.eval()\n",
    "    query_embedd = model.encode(query)\n",
    "    cosine_scores = util.pytorch_cos_sim(query_embedd, des_embeddings)\n",
    "    top5_matches = torch.argsort(cosine_scores, dim=-1, descending=True).tolist()[0][0:5]\n",
    "    return top5_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "6b7ce093",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "movie_id                                                   62\n",
      "title                                   2001: A Space Odyssey\n",
      "tags        Humanity finds a mysterious object buried bene...\n",
      "Name: 2970, dtype: object\n",
      "movie_id                                                19995\n",
      "title                                                  Avatar\n",
      "tags        In the 22nd century, a paraplegic Marine is di...\n",
      "Name: 0, dtype: object\n",
      "movie_id                                                10153\n",
      "title                                                  Sphere\n",
      "tags        The OSSA discovers a spacecraft thought to be ...\n",
      "Name: 549, dtype: object\n",
      "movie_id                                                17431\n",
      "title                                                    Moon\n",
      "tags        With only three weeks left in his three year c...\n",
      "Name: 3628, dtype: object\n",
      "movie_id                                                50357\n",
      "title                                               Apollo 18\n",
      "tags        Officially, Apollo 17 was the last manned miss...\n",
      "Name: 3608, dtype: object\n"
     ]
    }
   ],
   "source": [
    "query_show_des = 'moon Pandora space colony society Sam 3d'\n",
    "recommendded_results = recommend(query_show_des, model)\n",
    "\n",
    "for index in recommendded_results:\n",
    "    print(new.iloc[index,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "5492bff5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "movie_id     int64\n",
       "title       object\n",
       "tags        object\n",
       "review      object\n",
       "dtype: object"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new['tags'] = new['tags']\n",
    "new['review'] = new['tags']\n",
    "new.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "9c7e64bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, df, batch_size=32, learning_rate=0.01, epochs=30):\n",
    "\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    plots = df['tags'].values\n",
    "    \n",
    "    reviews = df['review'].values\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        for i in range(0, len(plots), batch_size):\n",
    "\n",
    "            batch_plots = plots[i:i+batch_size]\n",
    "            batch_reviews = reviews[i:i+batch_size]\n",
    "            \n",
    "            embedding_plots = torch.tensor(model.encode(batch_plots), requires_grad=True).unsqueeze(1)\n",
    "            embedding_reviews = torch.tensor(model.encode(batch_reviews), requires_grad=True).unsqueeze(1)\n",
    "            \n",
    "            loss = criterion(embedding_plots, embedding_reviews)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "bfb1f164",
   "metadata": {},
   "outputs": [],
   "source": [
    "train(model, new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfdf0b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_show_des = 'moon Pandora space colony society Sam 3d'\n",
    "recommendded_results = recommend(query_show_des, model)\n",
    "\n",
    "for index in recommendded_results:\n",
    "    print(new.iloc[index,:])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
