{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "6e9c2e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -U sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "0b2c1b9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\czhao\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from sentence_transformers import evaluation\n",
    "from sentence_transformers.cross_encoder import CrossEncoder\n",
    "import ast\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import nltk\n",
    "import re\n",
    "nltk.download('words')\n",
    "words = set(nltk.corpus.words.words())\n",
    "\n",
    "def stemSentence_porter(sentence):\n",
    "    porter = PorterStemmer()\n",
    "    token_words=word_tokenize(sentence)\n",
    "    stem_sentence=[]\n",
    "    for word in token_words:\n",
    "        stem_sentence.append(porter.stem(word))\n",
    "        stem_sentence.append(\" \")\n",
    "    return \"\".join(stem_sentence)\n",
    "\n",
    "def convert(text):\n",
    "    L = []\n",
    "    for i in ast.literal_eval(text):\n",
    "        L.append(i['name']) \n",
    "    return L \n",
    "\n",
    "\n",
    "def fetch_director(text):\n",
    "    L = []\n",
    "    for i in ast.literal_eval(text):\n",
    "        if i['job'] == 'Director':\n",
    "            L.append(i['name'])\n",
    "    return L \n",
    "\n",
    "\n",
    "def collapse(L):\n",
    "    L1 = []\n",
    "    for i in L:\n",
    "        L1.append(i.replace(\" \",\"\"))\n",
    "    return L1\n",
    "\n",
    "def clean_text(text):\n",
    "    # remove backslash-apostrophe \n",
    "    text = re.sub(\"\\'\", \"\", text) \n",
    "    # remove everything except alphabets \n",
    "    text = re.sub(\"[^a-zA-Z0-9,.’]\",\" \",text) \n",
    "    # remove whitespaces \n",
    "    text = ' '.join(text.split()) \n",
    "    # convert text to lowercase \n",
    "    \n",
    "    return text\n",
    "\n",
    "def get_cosine_sim(model, df):\n",
    "    scores = []\n",
    "    for row in zip(df['tags'], df['reviews']):\n",
    "        scores.append(util.cos_sim(model.encode(row[0]), model.encode(row[1])))\n",
    "    return scores\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "51f0e440",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = pd.read_csv('../tmdb_5000_data/tmdb_5000_movies.csv')\n",
    "credits = pd.read_csv('../tmdb_5000_data/tmdb_5000_credits.csv') \n",
    "movies = movies.merge(credits,on='title')\n",
    "\n",
    "reviews = pd.read_csv('../crawled_data/2022-11-19_movie_info_with_reviews.csv')\n",
    "reviews = reviews[['id','reviews']]\n",
    "movies = movies.merge(reviews,on='id', how='left')\n",
    "\n",
    "movies.dropna(inplace=True)\n",
    "movies['release_year'] = movies.release_date.apply(lambda x: x.split(\"-\")[0]).astype(int)\n",
    "movies = movies[movies['release_year']>1970]\n",
    "\n",
    "movies = movies[['movie_id','title','release_year','overview','genres','keywords','cast','crew','reviews']]\n",
    "movies.dropna(inplace=True)\n",
    "\n",
    "movies['genres'] = movies['genres'].apply(convert)\n",
    "\n",
    "movies['keywords'] = movies['keywords'].apply(convert)\n",
    "\n",
    "movies['cast'] = movies['cast'].apply(convert)\n",
    "\n",
    "movies['cast'] = movies['cast'].apply(lambda x:x[0:3])\n",
    "\n",
    "movies['crew'] = movies['crew'].apply(fetch_director)\n",
    "\n",
    "\n",
    "movies['crew'] = movies['crew'].apply(lambda x: [\" \".join(\\\n",
    "        w for w in nltk.wordpunct_tokenize(i) \\\n",
    "         if w.lower() in words or not w.isalpha()) for i in x])\n",
    "\n",
    "# movies['cast'] = movies['cast'].apply(collapse)\n",
    "# movies['crew'] = movies['crew'].apply(collapse)\n",
    "# movies['genres'] = movies['genres'].apply(collapse)\n",
    "# movies['keywords'] = movies['keywords'].apply(collapse)\n",
    "\n",
    "\n",
    "# new['tags'] = new['tags'].apply(stemSentence_porter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fde2e184",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies['reviews'] = movies['reviews'].apply(lambda x: clean_text(\"\".join(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5c9eadbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies['overview'] = movies['overview'].apply(lambda x:x.split())\n",
    "movies['release_year'] = movies['release_year'].astype(str).apply(lambda x:x.split())\n",
    "movies['tags'] = movies['overview'] + movies['genres'] + movies['release_year'] + movies['keywords'] + movies['cast'] + movies['crew'] \n",
    "new = movies.drop(columns=['overview','genres','keywords','cast','crew','release_year'])\n",
    "new['tags'] = new['tags'].apply(lambda x: \" \".join(x))\n",
    "new = new[(new['tags'].notnull())].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e1162e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "new = new[new['reviews']!=''].reset_index(drop=True)\n",
    "# new.to_csv(\"../tmdb_5000_data/Cleaned_Filtered_Plots_Reviews\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2b77bbd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>title</th>\n",
       "      <th>reviews</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19995</td>\n",
       "      <td>Avatar</td>\n",
       "      <td>Cameron’s epic can still thrill the audience w...</td>\n",
       "      <td>In the 22nd century, a paraplegic Marine is di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49026</td>\n",
       "      <td>The Dark Knight Rises</td>\n",
       "      <td>It still might not be quite the conclusion we ...</td>\n",
       "      <td>Following the death of District Attorney Harve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>49529</td>\n",
       "      <td>John Carter</td>\n",
       "      <td>John Carter is a good summer movie in March bu...</td>\n",
       "      <td>John Carter is a war-weary, former military ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>38757</td>\n",
       "      <td>Tangled</td>\n",
       "      <td>At its finest moments, this production emanate...</td>\n",
       "      <td>When the kingdom's most wanted-and most charmi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>767</td>\n",
       "      <td>Harry Potter and the Half-Blood Prince</td>\n",
       "      <td>...a for fans only entry within an often distr...</td>\n",
       "      <td>As Harry begins his sixth year at Hogwarts, he...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>943</th>\n",
       "      <td>42151</td>\n",
       "      <td>Down Terrace</td>\n",
       "      <td>A film that is compelling in its own right, wh...</td>\n",
       "      <td>After serving jail time for a mysterious crime...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>944</th>\n",
       "      <td>2292</td>\n",
       "      <td>Clerks</td>\n",
       "      <td>Clerks doesn’t feel as if it’s trying too hard...</td>\n",
       "      <td>Convenience and video store clerks Dante and R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>945</th>\n",
       "      <td>157185</td>\n",
       "      <td>Tin Can Man</td>\n",
       "      <td>Unique and eerie enough to be worth seeing, ev...</td>\n",
       "      <td>Recently dumped by his girlfirend for another ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>946</th>\n",
       "      <td>14337</td>\n",
       "      <td>Primer</td>\n",
       "      <td>Time travel may provide the paradoxical mechan...</td>\n",
       "      <td>Friends/fledgling entrepreneurs invent a devic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>947</th>\n",
       "      <td>126186</td>\n",
       "      <td>Shanghai Calling</td>\n",
       "      <td>A star is born in Daniel Henney in the predict...</td>\n",
       "      <td>When ambitious New York attorney Sam is sent t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>948 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     movie_id                                   title  \\\n",
       "0       19995                                  Avatar   \n",
       "1       49026                   The Dark Knight Rises   \n",
       "2       49529                             John Carter   \n",
       "3       38757                                 Tangled   \n",
       "4         767  Harry Potter and the Half-Blood Prince   \n",
       "..        ...                                     ...   \n",
       "943     42151                            Down Terrace   \n",
       "944      2292                                  Clerks   \n",
       "945    157185                             Tin Can Man   \n",
       "946     14337                                  Primer   \n",
       "947    126186                        Shanghai Calling   \n",
       "\n",
       "                                               reviews  \\\n",
       "0    Cameron’s epic can still thrill the audience w...   \n",
       "1    It still might not be quite the conclusion we ...   \n",
       "2    John Carter is a good summer movie in March bu...   \n",
       "3    At its finest moments, this production emanate...   \n",
       "4    ...a for fans only entry within an often distr...   \n",
       "..                                                 ...   \n",
       "943  A film that is compelling in its own right, wh...   \n",
       "944  Clerks doesn’t feel as if it’s trying too hard...   \n",
       "945  Unique and eerie enough to be worth seeing, ev...   \n",
       "946  Time travel may provide the paradoxical mechan...   \n",
       "947  A star is born in Daniel Henney in the predict...   \n",
       "\n",
       "                                                  tags  \n",
       "0    In the 22nd century, a paraplegic Marine is di...  \n",
       "1    Following the death of District Attorney Harve...  \n",
       "2    John Carter is a war-weary, former military ca...  \n",
       "3    When the kingdom's most wanted-and most charmi...  \n",
       "4    As Harry begins his sixth year at Hogwarts, he...  \n",
       "..                                                 ...  \n",
       "943  After serving jail time for a mysterious crime...  \n",
       "944  Convenience and video store clerks Dante and R...  \n",
       "945  Recently dumped by his girlfirend for another ...  \n",
       "946  Friends/fledgling entrepreneurs invent a devic...  \n",
       "947  When ambitious New York attorney Sam is sent t...  \n",
       "\n",
       "[948 rows x 4 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b6f134dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = SentenceTransformer('paraphrase-distilroberta-base-v1')\n",
    "# model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "# model = SentenceTransformer('all-mpnet-base-v2')\n",
    "# model = SentenceTransformer('stsb-bert-large')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c7e64bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train(model, df, batch_size=128, learning_rate=0.1, epochs=30):\n",
    "\n",
    "#     model.to(device)\n",
    "#     model.train()\n",
    "#     criterion = nn.MSELoss()\n",
    "#     optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "#     plots = df['tags'].values\n",
    "    \n",
    "#     reviews = df['reviews'].values\n",
    "\n",
    "#     for epoch in range(epochs):\n",
    "#         for i in range(0, len(plots), batch_size):\n",
    "\n",
    "#             batch_plots = plots[i:i+batch_size]\n",
    "#             batch_reviews = reviews[i:i+batch_size]\n",
    "            \n",
    "#             embedding_plots = torch.tensor(model.encode(batch_plots), requires_grad=True).unsqueeze(1).to(device)\n",
    "#             embedding_reviews = torch.tensor(model.encode(batch_reviews), requires_grad=True).unsqueeze(1).to(device)\n",
    "            \n",
    "#             loss = criterion(embedding_plots, embedding_reviews)\n",
    "#             print(loss)\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "#             optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bfb1f164",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# train(model, new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4c8710d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# descriptions = new['tags'].tolist()\n",
    "# des_embeddings = []\n",
    "# for i,des in enumerate(descriptions):\n",
    "#     des_embeddings.append(model.encode(des))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "01479e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def recommend(query, model):\n",
    "#     #Compute cosine-similarities with all embeddings \n",
    "#     model.eval()\n",
    "#     query_embedd = model.encode(query)\n",
    "#     cosine_scores = util.pytorch_cos_sim(query_embedd, des_embeddings)\n",
    "#     top5_matches = torch.argsort(cosine_scores, dim=-1, descending=True).tolist()[0][0:5]\n",
    "#     return top5_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cfdf0b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# query_show_des = 'moon Pandora space colony society Sam 3d'\n",
    "# recommendded_results = recommend(query_show_des, model)\n",
    "\n",
    "# for index in recommendded_results:\n",
    "#     print(new.iloc[index,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cbf6702a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import models, losses, InputExample\n",
    "from torch.utils.data import DataLoader\n",
    "from sentence_transformers import evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8341a9ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/mpnet-base were not used when initializing MPNetModel: ['lm_head.dense.bias', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.decoder.bias']\n",
      "- This IS expected if you are initializing MPNetModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing MPNetModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of MPNetModel were not initialized from the model checkpoint at microsoft/mpnet-base and are newly initialized: ['mpnet.pooler.dense.weight', 'mpnet.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# microsoft/mpnet-base\n",
    "# sentence-transformers/stsb-bert-large\n",
    "word_embedding_model = models.Transformer('microsoft/mpnet-base').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3562c1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension(), \n",
    "                                  pooling_mode_mean_tokens=True, \n",
    "                                  pooling_mode_cls_token=False, \n",
    "                                  pooling_mode_max_tokens=False\n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7908a249",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update the model\n",
    "sent_model = SentenceTransformer(modules=[word_embedding_model, pooling_model]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "f47d6c89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aaab98c77ac54360a4f8f4864dc09ed1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/730 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbe704526dad43178b2e2f965a29c81c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16f320e285174802a2430d0668881f37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/316 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbd7476d068a4e8eba0227d16f1e3d7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e752f4cc92664b5ab49c85f322d29e84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#model = CrossEncoder('cross-encoder/ms-marco-electra-base')\n",
    "model = CrossEncoder('cross-encoder/stsb-roberta-large')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "c8ddd1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = model.predict(new[['tags','reviews']].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "9f701ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_examples = []\n",
    "\n",
    "for index, row in enumerate(zip(new['tags'], new['reviews'])):\n",
    "    train_examples.append(InputExample(texts=[row[0], row[1]], label = [scores[index]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "63f1d288",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_examples, shuffle=True, batch_size=2)\n",
    "# MultipleNegativesRankingLoss not trainable because gpu limitation\n",
    "# MegaBatchMarginLoss \n",
    "# MSELoss need labels\n",
    "train_loss = losses.CosineSimilarityLoss(sent_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "720899d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_mse = evaluation.EmbeddingSimilarityEvaluator(new['tags'].values, new['reviews'].values,\\\n",
    "                                                  scores=scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "b147a3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dev_mse = evaluation.MSEEvaluator(new['tags'].values, new['reviews'].values,teacher_model=sent_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "804f0b56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39176ceb731a44099e731dc9509fbbec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22fd070a82e04876a4dfe079896d7c61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/474 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9e4c9479e4b44378376b6ea88bf40bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/474 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sent_model.fit(train_objectives=[(train_dataloader, train_loss)], epochs=2, warmup_steps=100, evaluator=dev_mse, output_path='result')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "35bdd903",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scores_after_training = get_cosine_sim(sent_model, new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "21691c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum(scores_before_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "f81110c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum(scores_after_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "544591e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptions = new['tags'].tolist()\n",
    "des_embeddings = []\n",
    "for i,des in enumerate(descriptions):\n",
    "    des_embeddings.append(sent_model.encode(des))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "9f0d160f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend(query, model):\n",
    "    #Compute cosine-similarities with all embeddings \n",
    "    model.eval()\n",
    "    query_embedd = model.encode(query)\n",
    "    cosine_scores = util.pytorch_cos_sim(query_embedd, des_embeddings)\n",
    "    top5_matches = torch.argsort(cosine_scores, dim=-1, descending=True).tolist()[0][0:5]\n",
    "    return top5_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "407e04df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "movie_id                                                 6171\n",
      "title                                            Dreamcatcher\n",
      "reviews     If this is what Stephen King movies have disin...\n",
      "tags        Four boyhood pals perform a heroic act and are...\n",
      "Name: 208, dtype: object\n",
      "movie_id                                                39053\n",
      "title                                                   Cyrus\n",
      "reviews     Cyrus is so spontaneous that it sometimes give...\n",
      "tags        With John's social life at a standstill and hi...\n",
      "Name: 749, dtype: object\n",
      "movie_id                                                74465\n",
      "title                                         We Bought a Zoo\n",
      "reviews     ...a movie that’s full of forced sentiment and...\n",
      "tags        Benjamin has lost his wife and, in a bid to st...\n",
      "Name: 280, dtype: object\n",
      "movie_id                                               356216\n",
      "title                                   The Rise of the Krays\n",
      "reviews     A plodding, methodical thriller that generates...\n",
      "tags        Follows the early years of two unknown 18 year...\n",
      "Name: 841, dtype: object\n",
      "movie_id                                                37786\n",
      "title                                      Sex and the City 2\n",
      "reviews     Offers a never ending journey of two hours and...\n",
      "tags        Carrie, Charlotte, and Miranda are all married...\n",
      "Name: 128, dtype: object\n"
     ]
    }
   ],
   "source": [
    "query_show_des = 'dinosaurs'\n",
    "recommendded_results = recommend(query_show_des, sent_model)\n",
    "\n",
    "for index in recommendded_results:\n",
    "    print(new.iloc[index,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e8710529",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "movie_id                                                 7278\n",
      "title                                       Meet the Spartans\n",
      "reviews     The worlds worst parody movie. , This is one o...\n",
      "tags        From the creators of Scary Movie and Date Movi...\n",
      "Name: 712, dtype: object\n",
      "movie_id                                                13805\n",
      "title                                          Disaster Movie\n",
      "reviews     Nothing more than a 90 minute barrage of unfun...\n",
      "tags        In DISASTER MOVIE, the filmmaking team behind ...\n",
      "Name: 886, dtype: object\n",
      "movie_id                                                82690\n",
      "title                                          Wreck-It Ralph\n",
      "reviews     Phil Johnston and Jennifer Lee’s script finds ...\n",
      "tags        Wreck-It Ralph is the 9-foot-tall, 643-pound v...\n",
      "Name: 72, dtype: object\n",
      "movie_id                                                93456\n",
      "title                                         Despicable Me 2\n",
      "reviews     Nothing is surprising about Despicable Me 2, b...\n",
      "tags        Gru is recruited by the Anti-Villain League to...\n",
      "Name: 300, dtype: object\n",
      "movie_id                                                77951\n",
      "title                                  Walking With Dinosaurs\n",
      "reviews     Top notch education and entertainment for dino...\n",
      "tags        Walking with Dinosaurs 3D is a film depicting ...\n",
      "Name: 289, dtype: object\n"
     ]
    }
   ],
   "source": [
    "query_show_des = 'Its Godzilla versus the paper pushers'\n",
    "recommendded_results = recommend(query_show_des, sent_model)\n",
    "\n",
    "for index in recommendded_results:\n",
    "    print(new.iloc[index,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0e09cb9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5fa680df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 97% |\n",
      "GPU Usage after emptying the cache\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  2% |  5% |\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from GPUtil import showUtilization as gpu_usage\n",
    "from numba import cuda\n",
    "\n",
    "def free_gpu_cache():\n",
    "    print(\"Initial GPU Usage\")\n",
    "    gpu_usage()                             \n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    cuda.select_device(0)\n",
    "    cuda.close()\n",
    "    cuda.select_device(0)\n",
    "\n",
    "    print(\"GPU Usage after emptying the cache\")\n",
    "    gpu_usage()\n",
    "\n",
    "free_gpu_cache()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7eeb4e38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d282d907",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
